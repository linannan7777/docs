<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.14" />
    <style>
      :root {
        --c-bg: #fff;
      }

      html.dark {
        --c-bg: #22272e;
      }

      html,
      body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia('(prefers-color-scheme: dark)').matches
      if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
        document.documentElement.classList.toggle('dark', true)
      }
    </script>
    <title>技术文档</title><meta name="description" content="温故而知新">
    <link rel="preload" href="/assets/style-BDZmSSuf.css" as="style"><link rel="stylesheet" href="/assets/style-BDZmSSuf.css">
    <link rel="modulepreload" href="/assets/app--wvp6Php.js"><link rel="modulepreload" href="/assets/第39课：爬虫框架Scrapy简介.html-DfAc0Mig.js">
    <link rel="prefetch" href="/assets/index.html-B191Uq_-.js" as="script"><link rel="prefetch" href="/assets/index.html-Dpj79eWa.js" as="script"><link rel="prefetch" href="/assets/第01课：初识Python.html-5mLKv2Qz.js" as="script"><link rel="prefetch" href="/assets/第02课：第一个Python程序.html-D_8eXP7J.js" as="script"><link rel="prefetch" href="/assets/第03课：Python语言元素之变量.html-DLSf2vun.js" as="script"><link rel="prefetch" href="/assets/第04课：Python语言元素之运算符.html-BX_9hgyi.js" as="script"><link rel="prefetch" href="/assets/第05课：分支结构.html-A5PWqctb.js" as="script"><link rel="prefetch" href="/assets/第06课：循环结构.html-C5aQFrNU.js" as="script"><link rel="prefetch" href="/assets/第07课：分支和循环结构的应用.html-BC3piN9x.js" as="script"><link rel="prefetch" href="/assets/第08课：常用数据结构之列表.html-DSw7kBUI.js" as="script"><link rel="prefetch" href="/assets/第09课：常用数据结构之元组.html-D33duBHJ.js" as="script"><link rel="prefetch" href="/assets/第10课：常用数据结构之字符串.html-P7p13Gxx.js" as="script"><link rel="prefetch" href="/assets/第11课：常用数据结构之集合.html-LaHIy1lt.js" as="script"><link rel="prefetch" href="/assets/第12课：常用数据结构之字典.html-2alKinTQ.js" as="script"><link rel="prefetch" href="/assets/第13课：函数和模块.html-DkNbukDE.js" as="script"><link rel="prefetch" href="/assets/第14课：函数的应用.html-DC8jmn87.js" as="script"><link rel="prefetch" href="/assets/第15课：函数使用进阶.html-B7QFvONW.js" as="script"><link rel="prefetch" href="/assets/第16课：函数的高级应用.html-CW55eJmd.js" as="script"><link rel="prefetch" href="/assets/第17课：面向对象编程入门.html-DiO7qBll.js" as="script"><link rel="prefetch" href="/assets/第18课：面向对象编程进阶.html-BLpDYJ42.js" as="script"><link rel="prefetch" href="/assets/第19课：面向对象编程应用.html-DJmj96Ux.js" as="script"><link rel="prefetch" href="/assets/第20课：Python标准库初探.html-B4gABPkd.js" as="script"><link rel="prefetch" href="/assets/第21课：文件读写和异常处理.html-DxoFrptj.js" as="script"><link rel="prefetch" href="/assets/第22课：对象的序列化和反序列化.html-D4cHHcHU.js" as="script"><link rel="prefetch" href="/assets/第23课：用Python读写CSV文件.html-CG9K3Fsx.js" as="script"><link rel="prefetch" href="/assets/第24课：用Python读写Excel文件-1.html-i4Bcshr1.js" as="script"><link rel="prefetch" href="/assets/第25课：用Python读写Excel文件-2.html-CapPYg6D.js" as="script"><link rel="prefetch" href="/assets/第26课：用Python操作Word文件和PowerPoint.html-BLqE8G4-.js" as="script"><link rel="prefetch" href="/assets/第27课：用Python操作PDF文件.html-op2vND2J.js" as="script"><link rel="prefetch" href="/assets/第28课：用Python处理图像.html-lXMt7unT.js" as="script"><link rel="prefetch" href="/assets/第29课：用Python发送邮件和短信.html-DGNA7_1V.js" as="script"><link rel="prefetch" href="/assets/第30课：正则表达式的应用.html-2Br1V5iQ.js" as="script"><link rel="prefetch" href="/assets/第31课：网络数据采集概述.html-C8GuQ5RG.js" as="script"><link rel="prefetch" href="/assets/第32课：用Python获取网络资源.html-CKEM5q2y.js" as="script"><link rel="prefetch" href="/assets/第33课：用Python解析HTML页面.html-DPvCBBeX.js" as="script"><link rel="prefetch" href="/assets/第34课：Python中的并发编程-1.html-C2jLR1L8.js" as="script"><link rel="prefetch" href="/assets/第35课：Python中的并发编程-2.html-DycR05ts.js" as="script"><link rel="prefetch" href="/assets/第36课：Python中的并发编程-3.html-BFBBqMIm.js" as="script"><link rel="prefetch" href="/assets/第37课：并发编程在爬虫中的应用.html-B9T81EKo.js" as="script"><link rel="prefetch" href="/assets/第38课：抓取网页动态内容.html-B9yYX7aV.js" as="script"><link rel="prefetch" href="/assets/第40课：关系型数据库和MySQL概述.html-CX0g4AQs.js" as="script"><link rel="prefetch" href="/assets/第41课.SQL详解之DDL.html-BlUvUghj.js" as="script"><link rel="prefetch" href="/assets/第42课.SQL详解之DML.html-WdcJZ-qA.js" as="script"><link rel="prefetch" href="/assets/第43课.SQL详解之DQL.html-CehSE-8A.js" as="script"><link rel="prefetch" href="/assets/第44课.SQL详解之DCL.html-VUBUwTJh.js" as="script"><link rel="prefetch" href="/assets/第45课.索引.html-Bx6pPrOT.js" as="script"><link rel="prefetch" href="/assets/第46课.视图_函数_过程.html-NBjrKSkK.js" as="script"><link rel="prefetch" href="/assets/第47课.MySQL新特性.html-GfszDmXE.js" as="script"><link rel="prefetch" href="/assets/第48课.Python程序接入MySQL数据库.html-TZheC2ii.js" as="script"><link rel="prefetch" href="/assets/404.html-BfYplzdF.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon"><!--[--><header class="vp-navbar"><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/"><img class="vp-site-logo" src="https://vuejs.press/images/hero.png" alt="技术文档"><span class="vp-site-name vp-hide-mobile" aria-hidden="true">技术文档</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="python"><span class="title">python</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="python"><span class="title">python</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link route-link-active auto-link" href="/python/Python-Core-50-Courses/" aria-label="50天基础"><!---->50天基础<!----></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><button class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar"><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="python"><span class="title">python</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="python"><span class="title">python</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link route-link-active auto-link" href="/python/Python-Core-50-Courses/" aria-label="50天基础"><!---->50天基础<!----></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading active"> <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link route-link-active auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/" aria-label="简介"><!---->简介<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC01%E8%AF%BE%EF%BC%9A%E5%88%9D%E8%AF%86Python.html" aria-label="第01课：初识Python"><!---->第01课：初识Python<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC02%E8%AF%BE%EF%BC%9A%E7%AC%AC%E4%B8%80%E4%B8%AAPython%E7%A8%8B%E5%BA%8F.html" aria-label="第02课：第一个Python程序"><!---->第02课：第一个Python程序<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC03%E8%AF%BE%EF%BC%9APython%E8%AF%AD%E8%A8%80%E5%85%83%E7%B4%A0%E4%B9%8B%E5%8F%98%E9%87%8F.html" aria-label="第03课：Python语言元素之变量"><!---->第03课：Python语言元素之变量<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC04%E8%AF%BE%EF%BC%9APython%E8%AF%AD%E8%A8%80%E5%85%83%E7%B4%A0%E4%B9%8B%E8%BF%90%E7%AE%97%E7%AC%A6.html" aria-label="第04课：Python语言元素之运算符"><!---->第04课：Python语言元素之运算符<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC05%E8%AF%BE%EF%BC%9A%E5%88%86%E6%94%AF%E7%BB%93%E6%9E%84.html" aria-label="第05课：分支结构"><!---->第05课：分支结构<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC06%E8%AF%BE%EF%BC%9A%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84.html" aria-label="第06课：循环结构"><!---->第06课：循环结构<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC07%E8%AF%BE%EF%BC%9A%E5%88%86%E6%94%AF%E5%92%8C%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84%E7%9A%84%E5%BA%94%E7%94%A8.html" aria-label="第07课：分支和循环结构的应用"><!---->第07课：分支和循环结构的应用<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC08%E8%AF%BE%EF%BC%9A%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%88%97%E8%A1%A8.html" aria-label="第08课：常用数据结构之列表"><!---->第08课：常用数据结构之列表<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC09%E8%AF%BE%EF%BC%9A%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%83%E7%BB%84.html" aria-label="第09课：常用数据结构之元组"><!---->第09课：常用数据结构之元组<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC10%E8%AF%BE%EF%BC%9A%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%AD%97%E7%AC%A6%E4%B8%B2.html" aria-label="第10课：常用数据结构之字符串"><!---->第10课：常用数据结构之字符串<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC11%E8%AF%BE%EF%BC%9A%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E9%9B%86%E5%90%88.html" aria-label="第11课：常用数据结构之集合"><!---->第11课：常用数据结构之集合<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC12%E8%AF%BE%EF%BC%9A%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%AD%97%E5%85%B8.html" aria-label="第12课：常用数据结构之字典"><!---->第12课：常用数据结构之字典<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC13%E8%AF%BE%EF%BC%9A%E5%87%BD%E6%95%B0%E5%92%8C%E6%A8%A1%E5%9D%97.html" aria-label="第13课：函数和模块"><!---->第13课：函数和模块<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC14%E8%AF%BE%EF%BC%9A%E5%87%BD%E6%95%B0%E7%9A%84%E5%BA%94%E7%94%A8.html" aria-label="第14课：函数的应用"><!---->第14课：函数的应用<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC15%E8%AF%BE%EF%BC%9A%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E8%BF%9B%E9%98%B6.html" aria-label="第15课：函数使用进阶"><!---->第15课：函数使用进阶<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC16%E8%AF%BE%EF%BC%9A%E5%87%BD%E6%95%B0%E7%9A%84%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8.html" aria-label="第16课：函数的高级应用"><!---->第16课：函数的高级应用<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC17%E8%AF%BE%EF%BC%9A%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8.html" aria-label="第17课：面向对象编程入门"><!---->第17课：面向对象编程入门<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC18%E8%AF%BE%EF%BC%9A%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E8%BF%9B%E9%98%B6.html" aria-label="第18课：面向对象编程进阶"><!---->第18课：面向对象编程进阶<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC19%E8%AF%BE%EF%BC%9A%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E5%BA%94%E7%94%A8.html" aria-label="第19课：面向对象编程应用"><!---->第19课：面向对象编程应用<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC20%E8%AF%BE%EF%BC%9APython%E6%A0%87%E5%87%86%E5%BA%93%E5%88%9D%E6%8E%A2.html" aria-label="第20课：Python标准库初探"><!---->第20课：Python标准库初探<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC21%E8%AF%BE%EF%BC%9A%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86.html" aria-label="第21课：文件读写和异常处理"><!---->第21课：文件读写和异常处理<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC22%E8%AF%BE%EF%BC%9A%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96.html" aria-label="第22课：对象的序列化和反序列化"><!---->第22课：对象的序列化和反序列化<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC23%E8%AF%BE%EF%BC%9A%E7%94%A8Python%E8%AF%BB%E5%86%99CSV%E6%96%87%E4%BB%B6.html" aria-label="第23课：用Python读写CSV文件"><!---->第23课：用Python读写CSV文件<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC24%E8%AF%BE%EF%BC%9A%E7%94%A8Python%E8%AF%BB%E5%86%99Excel%E6%96%87%E4%BB%B6-1.html" aria-label="第24课：用Python读写Excel文件-1"><!---->第24课：用Python读写Excel文件-1<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC25%E8%AF%BE%EF%BC%9A%E7%94%A8Python%E8%AF%BB%E5%86%99Excel%E6%96%87%E4%BB%B6-2.html" aria-label="第25课：用Python读写Excel文件-2"><!---->第25课：用Python读写Excel文件-2<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC26%E8%AF%BE%EF%BC%9A%E7%94%A8Python%E6%93%8D%E4%BD%9CWord%E6%96%87%E4%BB%B6%E5%92%8CPowerPoint.html" aria-label="第26课：用Python操作Word文件和PowerPoint"><!---->第26课：用Python操作Word文件和PowerPoint<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC27%E8%AF%BE%EF%BC%9A%E7%94%A8Python%E6%93%8D%E4%BD%9CPDF%E6%96%87%E4%BB%B6.html" aria-label="第27课：用Python操作PDF文件"><!---->第27课：用Python操作PDF文件<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC28%E8%AF%BE%EF%BC%9A%E7%94%A8Python%E5%A4%84%E7%90%86%E5%9B%BE%E5%83%8F.html" aria-label="第28课：用Python处理图像"><!---->第28课：用Python处理图像<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC29%E8%AF%BE%EF%BC%9A%E7%94%A8Python%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E5%92%8C%E7%9F%AD%E4%BF%A1.html" aria-label="第29课：用Python发送邮件和短信"><!---->第29课：用Python发送邮件和短信<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC30%E8%AF%BE%EF%BC%9A%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E5%BA%94%E7%94%A8.html" aria-label="第30课：正则表达式的应用"><!---->第30课：正则表达式的应用<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC31%E8%AF%BE%EF%BC%9A%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%A6%82%E8%BF%B0.html" aria-label="第31课：网络数据采集概述"><!---->第31课：网络数据采集概述<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC32%E8%AF%BE%EF%BC%9A%E7%94%A8Python%E8%8E%B7%E5%8F%96%E7%BD%91%E7%BB%9C%E8%B5%84%E6%BA%90.html" aria-label="第32课：用Python获取网络资源"><!---->第32课：用Python获取网络资源<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC33%E8%AF%BE%EF%BC%9A%E7%94%A8Python%E8%A7%A3%E6%9E%90HTML%E9%A1%B5%E9%9D%A2.html" aria-label="第33课：用Python解析HTML页面"><!---->第33课：用Python解析HTML页面<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC34%E8%AF%BE%EF%BC%9APython%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-1.html" aria-label="第34课：Python中的并发编程-1"><!---->第34课：Python中的并发编程-1<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC35%E8%AF%BE%EF%BC%9APython%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2.html" aria-label="第35课：Python中的并发编程-2"><!---->第35课：Python中的并发编程-2<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC36%E8%AF%BE%EF%BC%9APython%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-3.html" aria-label="第36课：Python中的并发编程-3"><!---->第36课：Python中的并发编程-3<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC37%E8%AF%BE%EF%BC%9A%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9C%A8%E7%88%AC%E8%99%AB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8.html" aria-label="第37课：并发编程在爬虫中的应用"><!---->第37课：并发编程在爬虫中的应用<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC38%E8%AF%BE%EF%BC%9A%E6%8A%93%E5%8F%96%E7%BD%91%E9%A1%B5%E5%8A%A8%E6%80%81%E5%86%85%E5%AE%B9.html" aria-label="第38课：抓取网页动态内容"><!---->第38课：抓取网页动态内容<!----></a><!----></li><li><a class="route-link route-link-active auto-link vp-sidebar-item active" href="/python/Python-Core-50-Courses/%E7%AC%AC39%E8%AF%BE%EF%BC%9A%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy%E7%AE%80%E4%BB%8B.html" aria-label="第39课：爬虫框架Scrapy简介"><!---->第39课：爬虫框架Scrapy简介<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC40%E8%AF%BE%EF%BC%9A%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8CMySQL%E6%A6%82%E8%BF%B0.html" aria-label="第40课：关系型数据库和MySQL概述"><!---->第40课：关系型数据库和MySQL概述<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC41%E8%AF%BE.SQL%E8%AF%A6%E8%A7%A3%E4%B9%8BDDL.html" aria-label="第41课.SQL详解之DDL"><!---->第41课.SQL详解之DDL<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC42%E8%AF%BE.SQL%E8%AF%A6%E8%A7%A3%E4%B9%8BDML.html" aria-label="第42课.SQL详解之DML"><!---->第42课.SQL详解之DML<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC43%E8%AF%BE.SQL%E8%AF%A6%E8%A7%A3%E4%B9%8BDQL.html" aria-label="第43课.SQL详解之DQL"><!---->第43课.SQL详解之DQL<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC44%E8%AF%BE.SQL%E8%AF%A6%E8%A7%A3%E4%B9%8BDCL.html" aria-label="第44课.SQL详解之DCL"><!---->第44课.SQL详解之DCL<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC45%E8%AF%BE.%E7%B4%A2%E5%BC%95.html" aria-label="第45课.索引"><!---->第45课.索引<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC46%E8%AF%BE.%E8%A7%86%E5%9B%BE_%E5%87%BD%E6%95%B0_%E8%BF%87%E7%A8%8B.html" aria-label="第46课.视图+函数+过程"><!---->第46课.视图+函数+过程<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC47%E8%AF%BE.MySQL%E6%96%B0%E7%89%B9%E6%80%A7.html" aria-label="第47课.MySQL新特性"><!---->第47课.MySQL新特性<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/python/Python-Core-50-Courses/%E7%AC%AC48%E8%AF%BE.Python%E7%A8%8B%E5%BA%8F%E6%8E%A5%E5%85%A5MySQL%E6%95%B0%E6%8D%AE%E5%BA%93.html" aria-label="第48课.Python程序接入MySQL数据库"><!---->第48课.Python程序接入MySQL数据库<!----></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div class="theme-default-content"><!--[--><!--]--><div><h2 id="第39课-爬虫框架scrapy简介" tabindex="-1"><a class="header-anchor" href="#第39课-爬虫框架scrapy简介"><span>第39课：爬虫框架Scrapy简介</span></a></h2><p>当你写了很多个爬虫程序之后，你会发现每次写爬虫程序时，都需要将页面获取、页面解析、爬虫调度、异常处理、反爬应对这些代码从头至尾实现一遍，这里面有很多工作其实都是简单乏味的重复劳动。那么，有没有什么办法可以提升我们编写爬虫代码的效率呢？答案是肯定的，那就是利用爬虫框架，而在所有的爬虫框架中，Scrapy 应该是最流行、最强大的框架。</p><h3 id="scrapy-概述" tabindex="-1"><a class="header-anchor" href="#scrapy-概述"><span>Scrapy 概述</span></a></h3><p>Scrapy 是基于 Python 的一个非常流行的网络爬虫框架，可以用来抓取 Web 站点并从页面中提取结构化的数据。下图展示了 Scrapy 的基本架构，其中包含了主要组件和系统的数据处理流程（图中带数字的红色箭头）。</p><p><img src="/assets/20210824003638-C6G4kw64.png" alt=""></p><h4 id="scrapy的组件" tabindex="-1"><a class="header-anchor" href="#scrapy的组件"><span>Scrapy的组件</span></a></h4><p>我们先来说说 Scrapy 中的组件。</p><ol><li>Scrapy 引擎（Engine）：用来控制整个系统的数据处理流程。</li><li>调度器（Scheduler）：调度器从引擎接受请求并排序列入队列，并在引擎发出请求后返还给它们。</li><li>下载器（Downloader）：下载器的主要职责是抓取网页并将网页内容返还给蜘蛛（Spiders）。</li><li>蜘蛛程序（Spiders）：蜘蛛是用户自定义的用来解析网页并抓取特定URL的类，每个蜘蛛都能处理一个域名或一组域名，简单的说就是用来定义特定网站的抓取和解析规则的模块。</li><li>数据管道（Item Pipeline）：管道的主要责任是负责处理有蜘蛛从网页中抽取的数据条目，它的主要任务是清理、验证和存储数据。当页面被蜘蛛解析后，将被发送到数据管道，并经过几个特定的次序处理数据。每个数据管道组件都是一个 Python 类，它们获取了数据条目并执行对数据条目进行处理的方法，同时还需要确定是否需要在数据管道中继续执行下一步或是直接丢弃掉不处理。数据管道通常执行的任务有：清理 HTML 数据、验证解析到的数据（检查条目是否包含必要的字段）、检查是不是重复数据（如果重复就丢弃）、将解析到的数据存储到数据库（关系型数据库或 NoSQL 数据库）中。</li><li>中间件（Middlewares）：中间件是介于引擎和其他组件之间的一个钩子框架，主要是为了提供自定义的代码来拓展 Scrapy 的功能，包括下载器中间件和蜘蛛中间件。</li></ol><h4 id="数据处理流程" tabindex="-1"><a class="header-anchor" href="#数据处理流程"><span>数据处理流程</span></a></h4><p>Scrapy 的整个数据处理流程由引擎进行控制，通常的运转流程包括以下的步骤：</p><ol><li><p>引擎询问蜘蛛需要处理哪个网站，并让蜘蛛将第一个需要处理的 URL 交给它。</p></li><li><p>引擎让调度器将需要处理的 URL 放在队列中。</p></li><li><p>引擎从调度那获取接下来进行爬取的页面。</p></li><li><p>调度将下一个爬取的 URL 返回给引擎，引擎将它通过下载中间件发送到下载器。</p></li><li><p>当网页被下载器下载完成以后，响应内容通过下载中间件被发送到引擎；如果下载失败了，引擎会通知调度器记录这个 URL，待会再重新下载。</p></li><li><p>引擎收到下载器的响应并将它通过蜘蛛中间件发送到蜘蛛进行处理。</p></li><li><p>蜘蛛处理响应并返回爬取到的数据条目，此外还要将需要跟进的新的 URL 发送给引擎。</p></li><li><p>引擎将抓取到的数据条目送入数据管道，把新的 URL 发送给调度器放入队列中。</p></li></ol><p>上述操作中的第2步到第8步会一直重复直到调度器中没有需要请求的 URL，爬虫就停止工作。</p><h3 id="安装和使用scrapy" tabindex="-1"><a class="header-anchor" href="#安装和使用scrapy"><span>安装和使用Scrapy</span></a></h3><p>可以使用 Python 的包管理工具<code>pip</code>来安装 Scrapy。</p><div class="language-Shell line-numbers-mode" data-highlighter="prismjs" data-ext="Shell" data-title="Shell"><pre class="language-Shell"><code><span class="line">pip install scrapy</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>在命令行中使用<code>scrapy</code>命令创建名为<code>demo</code>的项目。</p><div class="language-Bash line-numbers-mode" data-highlighter="prismjs" data-ext="Bash" data-title="Bash"><pre class="language-Bash"><code><span class="line">scrapy startproject demo</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>项目的目录结构如下图所示。</p><div class="language-Shell line-numbers-mode" data-highlighter="prismjs" data-ext="Shell" data-title="Shell"><pre class="language-Shell"><code><span class="line">demo</span>
<span class="line">|____ demo</span>
<span class="line">|________ spiders</span>
<span class="line">|____________ __init__.py</span>
<span class="line">|________ __init__.py</span>
<span class="line">|________ items.py</span>
<span class="line">|________ middlewares.py</span>
<span class="line">|________ pipelines.py</span>
<span class="line">|________ settings.py</span>
<span class="line">|____ scrapy.cfg</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>切换到<code>demo</code> 目录，用下面的命令创建名为<code>douban</code>的蜘蛛程序。</p><div class="language-Bash line-numbers-mode" data-highlighter="prismjs" data-ext="Bash" data-title="Bash"><pre class="language-Bash"><code><span class="line">scrapy genspider douban movie.douban.com</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="一个简单的例子" tabindex="-1"><a class="header-anchor" href="#一个简单的例子"><span>一个简单的例子</span></a></h4><p>接下来，我们实现一个爬取豆瓣电影 Top250 电影标题、评分和金句的爬虫。</p><ol><li><p>在<code>items.py</code>的<code>Item</code>类中定义字段，这些字段用来保存数据，方便后续的操作。</p><div class="language-Python line-numbers-mode" data-highlighter="prismjs" data-ext="Python" data-title="Python"><pre class="language-Python"><code><span class="line">import scrapy</span>
<span class="line"></span>
<span class="line"></span>
<span class="line">class DoubanItem(scrapy.Item):</span>
<span class="line">    title = scrapy.Field()</span>
<span class="line">    score = scrapy.Field()</span>
<span class="line">    motto = scrapy.Field()</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>修改<code>spiders</code>文件夹中名为<code>douban.py</code> 的文件，它是蜘蛛程序的核心，需要我们添加解析页面的代码。在这里，我们可以通过对<code>Response</code>对象的解析，获取电影的信息，代码如下所示。</p><div class="language-Python line-numbers-mode" data-highlighter="prismjs" data-ext="Python" data-title="Python"><pre class="language-Python"><code><span class="line">import scrapy</span>
<span class="line">from scrapy import Selector, Request</span>
<span class="line">from scrapy.http import HtmlResponse</span>
<span class="line"></span>
<span class="line">from demo.items import MovieItem</span>
<span class="line"></span>
<span class="line"></span>
<span class="line">class DoubanSpider(scrapy.Spider):</span>
<span class="line">    name = &#39;douban&#39;</span>
<span class="line">    allowed_domains = [&#39;movie.douban.com&#39;]</span>
<span class="line">    start_urls = [&#39;https://movie.douban.com/top250?start=0&amp;filter=&#39;]</span>
<span class="line"></span>
<span class="line">    def parse(self, response: HtmlResponse):</span>
<span class="line">        sel = Selector(response)</span>
<span class="line">        movie_items = sel.css(&#39;#content &gt; div &gt; div.article &gt; ol &gt; li&#39;)</span>
<span class="line">        for movie_sel in movie_items:</span>
<span class="line">            item = MovieItem()</span>
<span class="line">            item[&#39;title&#39;] = movie_sel.css(&#39;.title::text&#39;).extract_first()</span>
<span class="line">            item[&#39;score&#39;] = movie_sel.css(&#39;.rating_num::text&#39;).extract_first()</span>
<span class="line">            item[&#39;motto&#39;] = movie_sel.css(&#39;.inq::text&#39;).extract_first()</span>
<span class="line">            yield item</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通过上面的代码不难看出，我们可以使用 CSS 选择器进行页面解析。当然，如果你愿意也可以使用 XPath 或正则表达式进行页面解析，对应的方法分别是<code>xpath</code>和<code>re</code>。</p><p>如果还要生成后续爬取的请求，我们可以用<code>yield</code>产出<code>Request</code>对象。<code>Request</code>对象有两个非常重要的属性，一个是<code>url</code>，它代表了要请求的地址；一个是<code>callback</code>，它代表了获得响应之后要执行的回调函数。我们可以将上面的代码稍作修改。</p><div class="language-Python line-numbers-mode" data-highlighter="prismjs" data-ext="Python" data-title="Python"><pre class="language-Python"><code><span class="line">import scrapy</span>
<span class="line">from scrapy import Selector, Request</span>
<span class="line">from scrapy.http import HtmlResponse</span>
<span class="line"></span>
<span class="line">from demo.items import MovieItem</span>
<span class="line"></span>
<span class="line"></span>
<span class="line">class DoubanSpider(scrapy.Spider):</span>
<span class="line">    name = &#39;douban&#39;</span>
<span class="line">    allowed_domains = [&#39;movie.douban.com&#39;]</span>
<span class="line">    start_urls = [&#39;https://movie.douban.com/top250?start=0&amp;filter=&#39;]</span>
<span class="line"></span>
<span class="line">    def parse(self, response: HtmlResponse):</span>
<span class="line">        sel = Selector(response)</span>
<span class="line">        movie_items = sel.css(&#39;#content &gt; div &gt; div.article &gt; ol &gt; li&#39;)</span>
<span class="line">        for movie_sel in movie_items:</span>
<span class="line">            item = MovieItem()</span>
<span class="line">            item[&#39;title&#39;] = movie_sel.css(&#39;.title::text&#39;).extract_first()</span>
<span class="line">            item[&#39;score&#39;] = movie_sel.css(&#39;.rating_num::text&#39;).extract_first()</span>
<span class="line">            item[&#39;motto&#39;] = movie_sel.css(&#39;.inq::text&#39;).extract_first()</span>
<span class="line">            yield item</span>
<span class="line"></span>
<span class="line">        hrefs = sel.css(&#39;#content &gt; div &gt; div.article &gt; div.paginator &gt; a::attr(&quot;href&quot;)&#39;)</span>
<span class="line">        for href in hrefs:</span>
<span class="line">            full_url = response.urljoin(href.extract())</span>
<span class="line">            yield Request(url=full_url)</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>到这里，我们已经可以通过下面的命令让爬虫运转起来。</p><div class="language-Shell line-numbers-mode" data-highlighter="prismjs" data-ext="Shell" data-title="Shell"><pre class="language-Shell"><code><span class="line">scrapy crawl movie</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>可以在控制台看到爬取到的数据，如果想将这些数据保存到文件中，可以通过<code>-o</code>参数来指定文件名，Scrapy 支持我们将爬取到的数据导出成 JSON、CSV、XML 等格式。</p><div class="language-Shell line-numbers-mode" data-highlighter="prismjs" data-ext="Shell" data-title="Shell"><pre class="language-Shell"><code><span class="line">scrapy crawl moive -o result.json</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>不知大家是否注意到，通过运行爬虫获得的 JSON 文件中有<code>275</code>条数据，那是因为首页被重复爬取了。要解决这个问题，可以对上面的代码稍作调整，不在<code>parse</code>方法中解析获取新页面的 URL，而是通过<code>start_requests</code>方法提前准备好待爬取页面的 URL，调整后的代码如下所示。</p><div class="language-Python line-numbers-mode" data-highlighter="prismjs" data-ext="Python" data-title="Python"><pre class="language-Python"><code><span class="line">import scrapy</span>
<span class="line">from scrapy import Selector, Request</span>
<span class="line">from scrapy.http import HtmlResponse</span>
<span class="line"></span>
<span class="line">from demo.items import MovieItem</span>
<span class="line"></span>
<span class="line"></span>
<span class="line">class DoubanSpider(scrapy.Spider):</span>
<span class="line">    name = &#39;douban&#39;</span>
<span class="line">    allowed_domains = [&#39;movie.douban.com&#39;]</span>
<span class="line"></span>
<span class="line">    def start_requests(self):</span>
<span class="line">        for page in range(10):</span>
<span class="line">            yield Request(url=f&#39;https://movie.douban.com/top250?start={page * 25}&#39;)</span>
<span class="line"></span>
<span class="line">    def parse(self, response: HtmlResponse):</span>
<span class="line">        sel = Selector(response)</span>
<span class="line">        movie_items = sel.css(&#39;#content &gt; div &gt; div.article &gt; ol &gt; li&#39;)</span>
<span class="line">        for movie_sel in movie_items:</span>
<span class="line">            item = MovieItem()</span>
<span class="line">            item[&#39;title&#39;] = movie_sel.css(&#39;.title::text&#39;).extract_first()</span>
<span class="line">            item[&#39;score&#39;] = movie_sel.css(&#39;.rating_num::text&#39;).extract_first()</span>
<span class="line">            item[&#39;motto&#39;] = movie_sel.css(&#39;.inq::text&#39;).extract_first()</span>
<span class="line">            yield item</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>如果希望完成爬虫数据的持久化，可以在数据管道中处理蜘蛛程序产生的<code>Item</code>对象。例如，我们可以通过前面讲到的<code>openpyxl</code>操作 Excel 文件，将数据写入 Excel 文件中，代码如下所示。</p><div class="language-Python line-numbers-mode" data-highlighter="prismjs" data-ext="Python" data-title="Python"><pre class="language-Python"><code><span class="line">import openpyxl</span>
<span class="line"></span>
<span class="line">from demo.items import MovieItem</span>
<span class="line"></span>
<span class="line"></span>
<span class="line">class MovieItemPipeline:</span>
<span class="line"></span>
<span class="line">    def __init__(self):</span>
<span class="line">        self.wb = openpyxl.Workbook()</span>
<span class="line">        self.sheet = self.wb.active</span>
<span class="line">        self.sheet.title = &#39;Top250&#39;</span>
<span class="line">        self.sheet.append((&#39;名称&#39;, &#39;评分&#39;, &#39;名言&#39;))</span>
<span class="line"></span>
<span class="line">    def process_item(self, item: MovieItem, spider):</span>
<span class="line">        self.sheet.append((item[&#39;title&#39;], item[&#39;score&#39;], item[&#39;motto&#39;]))</span>
<span class="line">        return item</span>
<span class="line"></span>
<span class="line">    def close_spider(self, spider):</span>
<span class="line">        self.wb.save(&#39;豆瓣电影数据.xlsx&#39;)</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>上面的<code>process_item</code>和<code>close_spider</code>都是回调方法（钩子函数）， 简单的说就是 Scrapy 框架会自动去调用的方法。当蜘蛛程序产生一个<code>Item</code>对象交给引擎时，引擎会将该<code>Item</code>对象交给数据管道，这时我们配置好的数据管道的<code>parse_item</code>方法就会被执行，所以我们可以在该方法中获取数据并完成数据的持久化操作。另一个方法<code>close_spider</code>是在爬虫结束运行前会自动执行的方法，在上面的代码中，我们在这个地方进行了保存 Excel 文件的操作，相信这段代码大家是很容易读懂的。</p><p>总而言之，数据管道可以帮助我们完成以下操作：</p><ul><li>清理 HTML 数据，验证爬取的数据。</li><li>丢弃重复的不必要的内容。</li><li>将爬取的结果进行持久化操作。</li></ul></li><li><p>修改<code>settings.py</code>文件对项目进行配置，主要需要修改以下几个配置。</p><div class="language-Python line-numbers-mode" data-highlighter="prismjs" data-ext="Python" data-title="Python"><pre class="language-Python"><code><span class="line"># 用户浏览器</span>
<span class="line">USER_AGENT = &#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36&#39;</span>
<span class="line"></span>
<span class="line"># 并发请求数量 </span>
<span class="line">CONCURRENT_REQUESTS = 4</span>
<span class="line"></span>
<span class="line"># 下载延迟</span>
<span class="line">DOWNLOAD_DELAY = 3</span>
<span class="line"># 随机化下载延迟</span>
<span class="line">RANDOMIZE_DOWNLOAD_DELAY = True</span>
<span class="line"></span>
<span class="line"># 是否遵守爬虫协议</span>
<span class="line">ROBOTSTXT_OBEY = True</span>
<span class="line"></span>
<span class="line"># 配置数据管道</span>
<span class="line">ITEM_PIPELINES = {</span>
<span class="line">   &#39;demo.pipelines.MovieItemPipeline&#39;: 300,</span>
<span class="line">}</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p><strong>说明</strong>：上面配置文件中的<code>ITEM_PIPELINES</code>选项是一个字典，可以配置多个处理数据的管道，后面的数字代表了执行的优先级，数字小的先执行。</p></blockquote></li></ol></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: linannan@prosnav.com">linannan</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link auto-link prev" href="/python/Python-Core-50-Courses/%E7%AC%AC38%E8%AF%BE%EF%BC%9A%E6%8A%93%E5%8F%96%E7%BD%91%E9%A1%B5%E5%8A%A8%E6%80%81%E5%86%85%E5%AE%B9.html" aria-label="第38课：抓取网页动态内容"><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span>第38课：抓取网页动态内容</span></div></a><a class="route-link auto-link next" href="/python/Python-Core-50-Courses/%E7%AC%AC40%E8%AF%BE%EF%BC%9A%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8CMySQL%E6%A6%82%E8%BF%B0.html" aria-label="第40课：关系型数据库和MySQL概述"><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span>第40课：关系型数据库和MySQL概述</span></div></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app--wvp6Php.js" defer></script>
  </body>
</html>
